{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60805a91",
   "metadata": {},
   "source": [
    "\n",
    "<a id='chap-tpintroductionapprentissagesupervise'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39e4dc2",
   "metadata": {},
   "source": [
    "# Travaux pratiques - Introduction à l’apprentissage supervisé\n",
    "\n",
    "**L’objectif** de cette première séance de travaux pratiques est de vous faire découvrir les problèmes de classification et les problèmes de régression à l'aide de modèles simples : régressions linéaires et polynomiales et arbres de décision.\n",
    "\n",
    "Références externes utiles :\n",
    "- [Documentation NumPy](https://docs.scipy.org/doc/numpy/user/index.html)  \n",
    "- [Documentation SciPy](https://docs.scipy.org/doc/scipy/reference/)  \n",
    "- [Documentation MatPlotLib](http://matplotlib.org/)  \n",
    "- [Documentation de scikit-learn](http://scikit-learn.org/stable/index.html)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c0a9f2",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Import des bibliothèques utiles\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256f74b6",
   "metadata": {},
   "source": [
    "## Régression avec modèles linéaires et polynomiaux\n",
    "\n",
    "Pour commencer ce premier TP, nous examinerons un problème simple de\n",
    "régression avec une seule variable prédictive, similaire à celui\n",
    "illustré dans le support de cours. À partir d’un ensembles\n",
    "d’observations $ \\{(x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n)\\} $,\n",
    "l’objectif est de trouver la fonction $ \\hat{f} $ telle que\n",
    "$ \\hat{f}(x_i) = y_i $.\n",
    "\n",
    "Pour cet exemple, commençons par générer des données synthétiques. En\n",
    "pratique, nous n’aurions bien entendu pas à réaliser ce travail : le jeu\n",
    "de données est constitué des observations réelles. Notre jeu de données\n",
    "d’exemple consiste en une portion de sinusoïde sur laquelle un bruit\n",
    "gaussien a été appliqué."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af77aec5",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Fixe l'aléas pour pouvoir reproduire les résultats\n",
    "np.random.seed(0)\n",
    "# On tire au hasard 100 points dans l'intervalle [0,2]\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "# On calcule la valeur de sin(x) pour chaque point, plus un bruit gaussien aléatoire\n",
    "y = np.sin(X[:,0]) + 0.15 * np.random.randn(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae4ed7b",
   "metadata": {},
   "source": [
    "Nous pouvons visualisation toutes les données générées, qui forment\n",
    "notre matrice d’observation pour ce problème de régression :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf6fa18",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X, y, s=50)\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe2ddf4",
   "metadata": {},
   "source": [
    "Nous générons maintenant un premier découpage entre données d’apprentissage et données de test. Ce découpage est aléatoire et\n",
    "s’effectue à l’aide de la fonction [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "de scikit-learn. Le paramètre `test_size` permet de spécifier le pourcentage du jeu de données qui sera contenu dans le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357aff11",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_train, y_train, s=50, edgecolors='none', label=\"Exemples d'entraînement\")\n",
    "plt.scatter(X_test, y_test, c='none', s=50, edgecolors='blue', label=\"Exemples d'évaluation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dae1b8",
   "metadata": {},
   "source": [
    "Nous cherchons d’abord un modèle linéaire pour ce problème de régression. Regardez la classe\n",
    "[LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression)\n",
    "de scikit-learn (ainsi que [ces explications](http://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares)).\n",
    "Dans le cas présent, scikit-learn va chercher la fonction affine $ f: x \\rightarrow y = ax + b $ en déterminant les paramètres\n",
    "$ a $ et $ b $ à l’aide de la méthode des moindres carrés.\n",
    "\n",
    "Les résultats sont évalués ici à travers le **coefficient de détermination**, qui est le rapport entre la variance expliquée par le\n",
    "modèle et la variance totale (de la variable expliquée), voir [les explications](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html).\n",
    "\n",
    "Commençons par instancier un modèle de régression linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce854d9c",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bb8cb9",
   "metadata": {},
   "source": [
    "Tous les modèles implémentés dans scikit-learn suivent la même interface et présentent au moins les trois méthodes suivantes :\n",
    "\n",
    "- `.fit()` permet d’apprendre le modèle en estimant ses paramètres à\n",
    "  partir d’un jeu de données,  \n",
    "- `.predict()` ou `.transform()` permet d’appliquer le modèle à de\n",
    "  nouvelles données,  \n",
    "- `.score()` permet d’évaluer le modèle selon un critère prédéfini\n",
    "  (taux de bonne classification, coefficient de détermination, etc.)\n",
    "  sur un jeu de test.  \n",
    "\n",
    "\n",
    "Par exemple, dans notre cas, la méthode `.fit(X,y)` permet de déterminer les paramètres de la régression linéaire à partir de nos\n",
    "observations `X` et de notre vérité terrain `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fac9fd",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# optimisation du modèle: détermination des paramètres de la régression linéaire par la méthode des moindres carrés\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d745cec",
   "metadata": {},
   "source": [
    "Nous pouvons évaluer à quel point le modèle « colle » aux données à l’aide du coefficient de détermination calculé sur les exemples du jeu\n",
    "d’apprentissage :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6a17cf",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# attention, score() ici ne renvoie pas l'erreur mais la valeur du coefficient de détermination R² !\n",
    "coeff_train = reg.score(X_train, y_train)\n",
    "print(f\"Coefficient de détermination R² en train : {coeff_train:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa88072f",
   "metadata": {},
   "source": [
    "## Question:\n",
    "\n",
    "Calculer le coefficient de détermination R² sur le jeu de test. Que constatez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3e536e-c10d-41d0-8764-ad1616c6b335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67e79da1",
   "metadata": {},
   "source": [
    "Nous pouvons ensuite, à partir des coefficients qui ont été estimés,\n",
    "tracer notre modèle de régression :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52715a08",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_train,y_train, s=50, edgecolors='none', label=\"Exemples d'apprentissage\")\n",
    "plt.scatter(X_test,y_test, c='none', s=50, edgecolors='blue', label=\"Exemples d'évaluation\")\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "\n",
    "x_min, x_max = plt.xlim()\n",
    "nx = 100\n",
    "xx = np.linspace(x_min, x_max, nx).reshape(-1,1)\n",
    "plt.plot(xx,reg.predict(xx), color='k', label=\"Régression linéaire\")\n",
    "plt.title(\"Régression linéaire unidimensionnelle\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf97e09",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "Calculez l’erreur quadratique moyenne du modèle sur les données d’apprentissage et ensuite sur les données de test. Vous pouvez\n",
    "l’implémenter vous-même à l’aide de NumPy ou bien consulter la [documentation du module\n",
    "sklearn.metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e0d77b-ceae-4e75-8153-869f732b2066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf5efe20",
   "metadata": {},
   "source": [
    "### Régression polynomiale\n",
    "\n",
    "La régression linéaire est un outil pratique mais quelque peu limité : les relations entre les variables explicatives et la variable à prédire\n",
    "sont rarement linéaires en pratique ! Nous pourrions chercher dans une famille paramétrique plus grande, par exemple les polynômes à une seule\n",
    "variable de degré $ d $ : $ P : x \\rightarrow a_0 + a_1 x + a_2 x^2 + \\dots + a_d x^d $.\n",
    "\n",
    "La visualisation interactive ci-dessous permet de visualiser les résultats d’une régression polynomiale appliquée sur notre jeu de\n",
    "données, de tracer la régression et d’afficher les coefficients de détermination R² en apprentissage et en test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52774b76",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from ipywidgets import interact, fixed\n",
    "\n",
    "@interact(degree=(0,10,1), show=fixed(True))\n",
    "def polynomial_fit(degree, show=False):\n",
    "    pipe = Pipeline([('poly', PolynomialFeatures(degree=degree)),\n",
    "                    ('reg', linear_model.LinearRegression())])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    train_score = pipe.score(X_train, y_train)\n",
    "    test_score = pipe.score(X_test, y_test)\n",
    "\n",
    "    if show:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(X_train, y_train, s=50, edgecolors='none', label=\"Exemples d'apprentissage\")\n",
    "        plt.scatter(X_test, y_test, c='none', s=50, edgecolors='blue', label=\"Exemples de test\")\n",
    "        x_min, x_max = plt.xlim()\n",
    "        xx = np.linspace(x_min, x_max, nx).reshape(-1,1)\n",
    "        plt.plot(xx,pipe.predict(xx),color='black', label=\"Régression polynomiale\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"Coefficient R² (train): {train_score:.3f}\")\n",
    "        print(f\"Coefficient R² (test): {test_score:.3f}\")\n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e365cea3",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Que se passe-t-il lorsque l’on modifie le degré du polynôme ? Quelles observations pouvez-vous faire concernant le sous-apprentissage ? Le sur-apprentissage ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43f99b9",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "*(pour aller plus loin)* Tracer les courbes du coefficient R² sur le jeu d’apprentissage et sur le jeu de test en fonction du degré du polynôme (entre 1 et 10). Vous\n",
    "pouvez utiliser la fonction `polynomial_fit` pour ce faire qui renvoie un tuple contenant les deux scores. Que constatez-vous ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0d76a2",
   "metadata": {},
   "source": [
    "## Classification avec modèles linéaires et non-linéaires\n",
    "\n",
    "Voyons maintenant comment les notions de sur-apprentissage et sous-apprentissage peuvent se manifester dans le cas d’un problème de\n",
    "classement (ou classification). Nous examinerons un problème simple de discrimination entre deux classes, similaire à celui illustré dans le\n",
    "support de cours.\n",
    "\n",
    "Nous générons des données à partir de lois normales bidimensionnelles. Pour la première classe nous employons une seule loi avec des variances\n",
    "différentes et une rotation qui introduit des covariances. La seconde classe est un mélange de 4 lois normales avec des centres différents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbf162a",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# fixer la graine aléatoire de numpy permet d'obtenir systématiquement les mêmes résultats\n",
    "np.random.seed(150)\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "dataset = \"gaussian\"\n",
    "\n",
    "if dataset == \"gaussian\":\n",
    "    # définir matrices de rotation et de dilatation\n",
    "    rot = np.array([[0.94, -0.34], [0.34, 0.94]])\n",
    "    sca = np.array([[3.4, 0], [0, 2]])\n",
    "    # générer données classe 1\n",
    "    c1d = (np.random.randn(200,2)).dot(sca).dot(rot)\n",
    "\n",
    "    # générer données classe 2\n",
    "    c2d1 = np.random.randn(25,2)+[-10, 2]\n",
    "    c2d2 = np.random.randn(25,2)+[-7, -2]\n",
    "    c2d3 = np.random.randn(25,2)+[-2, -6]\n",
    "    c2d4 = np.random.randn(25,2)+[5, -7]\n",
    "\n",
    "    data = np.concatenate((c1d, c2d1, c2d2, c2d3, c2d4))\n",
    "\n",
    "    # générer étiquettes de classe\n",
    "    l1c = np.ones(200, dtype=int)\n",
    "    l2c = np.zeros(100, dtype=int)\n",
    "    labels = np.concatenate((l1c, l2c))\n",
    "elif dataset == \"iris\":\n",
    "    iris_X, iris_y = datasets.load_iris(return_X_y=True)\n",
    "    data = iris_X[:, :2]\n",
    "    labels = iris_y\n",
    "elif dataset == \"wine\":\n",
    "    wine_X, wine_y = datasets.load_wine(return_X_y=True)\n",
    "    data = wine_X[:, (0,10)]\n",
    "    labels = wine_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0232d4ba",
   "metadata": {},
   "source": [
    "Visualisation de toutes les données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651fcfdd",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# les échantillons du premier groupe sont en rouge 'r', ceux du deuxième groupe en vert (\"green\") 'g'\n",
    "cmp = np.array(['r','g', 'b'])\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(data[:,0],data[:,1], c=cmp[labels], s=50, edgecolors='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe62dbf",
   "metadata": {},
   "source": [
    "Nous générons maintenant un premier découpage entre données d’apprentissage et données de test. Les données de test sont affichées\n",
    "avec cercles vides (`c='none'`), les données d’apprentissage avec des cercles remplis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1b7d18",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# découpage des données en train et test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.33, random_state=0)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_train[:,0],X_train[:,1],c=cmp[y_train], s=50, edgecolors='none', label=\"Exemples d'apprentissage\")\n",
    "plt.scatter(X_test[:,0], X_test[:,1], c='none' ,s=50, edgecolors=cmp[y_test], label=\"Exemples de test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc61e410",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "Combien d’échantillons le jeu de données d’apprentissage contient-il ? La [documentation de scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "peut vous aider."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b94d45",
   "metadata": {},
   "source": [
    "### Modèle linéaire : SVM\n",
    "\n",
    "Nous cherchons d’abord un modèle linéaire pour ce problème de discrimination entre deux classes et utilisons pour cela une machine à vecteur de support (SVM). En résumé, cette méthode cherche la frontière de décision linéaire qui sépare au mieux les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b695768",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm = LinearSVC()\n",
    "\n",
    "# évaluation et affichage sur split1\n",
    "svm.fit(X_train, y_train)\n",
    "print(\"Le score sur le jeu d'apprentissage est de : {:.3f}\".format(svm.score(X_train, y_train)))\n",
    "\n",
    "print(\"Le score sur le jeu de test est de : {:.3f}\".format(svm.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10913f45",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "À l’aide de la documentation de scikit-learn, déterminez à quoi correspond la valeur renvoyée par la méthode .score()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17056eda",
   "metadata": {},
   "source": [
    "Nous pouvons examiner visuellement le modèle trouvé (la frontière de\n",
    "discrimination linéaire, c’est-à-dire ici une droite dans le plan) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556b946f",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# on créé une nouvelle figure sur laquelle on affiche les points\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_train[:,0], X_train[:,1], c=cmp[y_train], s=50, edgecolors='none', label=\"Train\")\n",
    "plt.scatter(X_test[:,0],  X_test[:,1], c='none', s=50, edgecolors=cmp[y_test], label=\"Test\")\n",
    "\n",
    "# on calcule pour chaque point du plan sa probabilité d'appartenir à chaque classe\n",
    "nx, ny = 400, 400\n",
    "x_min, x_max = plt.xlim()\n",
    "y_min, y_max = plt.ylim()\n",
    "# meshgrid permet d'échantillonner tous les points du plan (entre x_min et x_max)\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, nx),np.linspace(y_min, y_max, ny))\n",
    "# .decision_function permet d'obtenir le \"score\" assigné par la SVM à chaque observation\n",
    "Z = svm.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "#for cls_idx in range(max(labels)):\n",
    "zz = Z.reshape(xx.shape)\n",
    "# on dessine la frontière correspond à un score de 0,5\n",
    "# les scores < 0,5 correspondent à la classe 0\n",
    "# les scores > 0,5 correspondent à la classe 1\n",
    "plt.contour(xx, yy, zz, [0.5])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cc7f09-3952-4662-a97e-d96656288a3f",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "À l'aide de la [documentation de scikit-learn](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics), calculez la matrice de confusion du modèle, ainsi que son exactitude (*accuracy*).\n",
    "\n",
    "Au-delà de quelle performance peut-on considérer que le modèle a appris quelque chose ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afff442-4989-4cae-aeaf-cf4d56ea3103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c9ce0ae-482e-4325-b8f7-3aa05ec64267",
   "metadata": {},
   "source": [
    "Comme le jeu de de données est déséquilibré (il y a plus de données de la classe 2 que de la classe 1), la baseline à battre est un modèle qui prédirait systématiquement la classe majoritaire, ici la classe 2 : ce modèle obtiendrait ~66% d'*accuracy*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712837a",
   "metadata": {},
   "source": [
    "### Modèle non-linéaire: arbre de classification\n",
    "\n",
    "Comme vous avez pu le constater, la frontière de séparation idéale entre les deux groupes n’est pas linéaire. Il nous faut donc changer de\n",
    "famille paramétrique pour en choisir une de plus grande capacité. Nous allons donc utiliser un arbre de décision pour réaliser la classification binaire. Nous utilisons\n",
    "pour cela la classe [MLPClassifier](https://scikit-learn.org/stable/modules/tree.html)\n",
    "de scikit-learn. Il est très\n",
    "instructif d’examiner [les valeurs par défaut des paramètres](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier).\n",
    "\n",
    "Il n’est pas indispensable de connaître le fonctionnement précis des arbres de décision pour ce TP, toutefois si le sujet vous intéresse vous pouvez consulter [ce cours](https://cedric.cnam.fr/vertigo/Cours/ml2/coursArbresDecision.html).\n",
    "\n",
    "Le principal paramètre que nous allons manipuler est la profondeur maximale de l'arbre. Par défaut, scikit-learn ne limite pas la profondeur et l'arbre peut être aussi profond que nécessaire pour que toutes les feuilles ne contiennent que des observations de la même classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff46c69",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=None)\n",
    "\n",
    "# évaluation et affichage sur split1\n",
    "clf.fit(X_train, y_train)\n",
    "train_score = clf.score(X_train, y_train)\n",
    "print(f\"Le score en train est {train_score:.3f}\")\n",
    "\n",
    "test_score = clf.score(X_test, y_test)\n",
    "print(f\"Le score en test est {test_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6233fd",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# créer une nouvelle figure\n",
    "plt.figure()\n",
    "# afficher les nuages de points apprentissage (remplis) et de test (vides)\n",
    "plt.scatter(X_train[:,0],X_train[:,1],c=cmp[y_train],s=50, edgecolors='none', label=\"Train\")\n",
    "plt.scatter(X_test[:,0], X_test[:,1], c='none', s=50, edgecolors=cmp[y_test], label=\"Test\")\n",
    "\n",
    "# calculer la probabilité de sortie du perceptron pour tous les points du plan\n",
    "nx, ny = 200, 200\n",
    "x_min, x_max = plt.xlim()\n",
    "y_min, y_max = plt.ylim()\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, nx),np.linspace(y_min, y_max, ny))\n",
    "Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
    "for cls_idx in range(max(labels)):\n",
    "    zz = Z[:, cls_idx].reshape(xx.shape)\n",
    "    # on dessine la frontière correspond à un score de 0,5\n",
    "    # les scores < 0,5 correspondent à la classe 0\n",
    "    # les scores > 0,5 correspondent à la classe 1\n",
    "    plt.contour(xx, yy, zz, [0.5])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cff938",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Refaites l’expérience avec `max_depth = 2`. Dans quel cas la régularisation est plus forte ? Quelle est la conséquence sur les résultats ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e85d50-a201-44d3-b28e-5d8c9909151e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4e69ef",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "@interact(max_depth=widgets.IntSlider(min=1, max=10, step=1))\n",
    "def tree_fit(max_depth):\n",
    "    clf = DecisionTreeClassifier(max_depth=max_depth)\n",
    "\n",
    "    # évaluation et affichage sur split1\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    print(f\"Le score en train est {train_score:.3f}\")\n",
    "\n",
    "    test_score = clf.score(X_test, y_test)\n",
    "    print(f\"Le score en test est {test_score:.3f}\")\n",
    "\n",
    "    # on créé une nouvelle figure sur laquelle on affiche les points\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(X_train[:,0], X_train[:,1], c=cmp[y_train], s=50, edgecolors='none', label=\"Train\")\n",
    "    plt.scatter(X_test[:,0],  X_test[:,1], c='none', s=50, edgecolors=cmp[y_test], label=\"Test\")\n",
    "\n",
    "    # on calcule pour chaque point du plan sa probabilité d'appartenir à chaque classe\n",
    "    nx, ny = 400, 400\n",
    "    x_min, x_max = plt.xlim()\n",
    "    y_min, y_max = plt.ylim()\n",
    "    # meshgrid permet d'échantillonner tous les points du plan (entre x_min et x_max)\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, nx),np.linspace(y_min, y_max, ny))\n",
    "    # .predict_proba permet de prédire le score de chaque classe pour un ensemble d'observations\n",
    "    Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
    "    for cls_idx in range(max(labels)):\n",
    "        zz = Z[:, cls_idx].reshape(xx.shape)\n",
    "        # on dessine la frontière correspond à un score de 0,5\n",
    "        # les scores < 0,5 correspondent à la classe 0\n",
    "        # les scores > 0,5 correspondent à la classe 1\n",
    "        plt.contour(xx, yy, zz, [0.5])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa36ccf",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Expérimentez avec la visualisation ci-dessus. Que se passe-t-il lorsque la profondeur augmente ? Lorsqu'elle diminue ?\n",
    "Comment pouvez-vous interpréter ces résultats du point de vue de la capacité du modèle, du sur-apprentissage et du sous-apprentissage ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e34eb98-a471-48f7-9722-e5ae81f6482f",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "À l'aide de la fonction [classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report) de scikit-learn, affichez les performances de classification du modèle obtenu. Quelles sont les métriques utilisées par scikit-learn ? À quoi correspondent-elles ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b180df-1787-44be-be4a-531d99f99a32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "date": 1713271565.5039783,
  "filename": "tpIntroductionApprentissageSupervise.rst",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "title": "Travaux pratiques - Introduction à l’apprentissage supervisé"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
