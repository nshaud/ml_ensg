{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db4182d7-0580-483e-8b00-316cd6708479",
   "metadata": {},
   "source": [
    "# Travaux pratiques - Classification des sols\n",
    "\n",
    "**L’objectif** de cette deuxième séance de travaux pratiques est de vous faire manipuler des données réelles pour une tâche de classification de couverture des sols à partir d'images aériennes ou satellitaires.\n",
    "\n",
    "Références externes utiles :\n",
    "- [Documentation NumPy](https://docs.scipy.org/doc/numpy/user/index.html)  \n",
    "- [Documentation SciPy](https://docs.scipy.org/doc/scipy/reference/)  \n",
    "- [Documentation MatPlotLib](http://matplotlib.org/)  \n",
    "- [Documentation de scikit-learn](http://scikit-learn.org/stable/index.html)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77361db-b769-4384-a669-92f9a00b6127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e07e8f5-099d-491c-845b-22aae1f96db0",
   "metadata": {},
   "source": [
    "## Évaluation des modèles et corrélations spatiales\n",
    "\n",
    "Pour commencer, nous allons considérer le jeu de données *Pavia University*. Il s'agit d'une image hyperspectrale annotée de $610\\times340$ pixels, comprenant 103 bandes spectrales. L'acquisitition a été réalisée à l'aide du spectromètre ROSIS-3, et couvre une partie de l'université de Pavie en Italie. Le jeu de données total comporte ainsi 42776 pixels annotés dans 9 classes différentes : *asphalt*, *meadows*, *gravel*, *trees*, *metal sheet*, *bare soil*, *bitumen*, *brick*, et *shadow*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5610c75c-4559-4510-a995-42ea82ead3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "from urllib.request import urlretrieve\n",
    "urlretrieve(\"https://www.ehu.eus/ccwintco/uploads/e/ee/PaviaU.mat\", \"PaviaU.mat\")\n",
    "urlretrieve(\"https://www.ehu.eus/ccwintco/uploads/5/50/PaviaU_gt.mat\", \"PaviaU_gt.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4baf70-2832-4990-942d-8f7d7f09581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pavia_image = loadmat(\"PaviaU.mat\")[\"paviaU\"]\n",
    "pavia_gt = loadmat(\"PaviaU_gt.mat\")[\"paviaU_gt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3d8849-d538-4ef0-9077-63feffdf21f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_bands = (55,41,12)\n",
    "pavia_rgb = pavia_image[:,:,rgb_bands]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.imshow((pavia_rgb - pavia_rgb.min()) / pavia_rgb.max())\n",
    "plt.title(\"Image pseudo-RGB\")\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.imshow(pavia_gt, cmap=\"Pastel1\")\n",
    "plt.title(\"Vérité terrain\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76945ec9-f5a3-4018-8afe-0e014bfc7260",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant mettre en forme le jeu de données pour son traitement avec scikit-learn. L'opération dans notre cas consiste à formater les pixels (de train puis de test) sous forme d'une liste de vecteurs (chaque vecteur correspondant aux réflectances de 103 bandes spectrales). C'est donc un simple redimensionnement avec numpy. Attention toutefois, une subtilité de ce jeu de données est que la classe 0 correspond en réalité aux pixels *non annotés* : il faut donc les retirer (on ne souhaite ni s'entraîner dessus, ni s'évaluer dessus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be3d408-93ed-4ece-9f71-5c429316ef06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le jeu de données contient seulement les pixels pour lesquels la vérité terrain est non-nulle \n",
    "X = pavia_image[pavia_gt != 0].reshape(-1, 103)\n",
    "y = pavia_gt[pavia_gt != 0].reshape(-1)\n",
    "\n",
    "nonzero_coordinates = np.nonzero(pavia_gt)\n",
    "coordinates = np.array(list(zip(*nonzero_coordinates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b07949c-6908-46c2-a607-a1ece31307a6",
   "metadata": {},
   "source": [
    "Pour commencer, tirons aléatoirement 10% des pixels dans l'image pour constituer un jeu d'apprentissage. Le reste des pixels constituera le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837e555f-9b75-41de-9120-cd2add117523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, X_coords_train, X_coords_test, y_train, y_test = train_test_split(X, coordinates, y, train_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9b754-60aa-4fff-9d24-853a70167b5b",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Que représente la matrice `coordinates` ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322d5ffd-bbc4-4d9a-b5ca-bd892d3b0e46",
   "metadata": {},
   "source": [
    "### Correction\n",
    "\n",
    "Il s'agit de la matrice qui a pour valeur le tuplet $(i,j)$ aux coordonnées $(i,j)$. Autrement dit, chaque élément représente ses propres coordonnées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a1ad88-2a0b-4fc6-8097-f129807e156c",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Appliquer une classification par k-plus proches voisins avec $k=5$ en utilisant comme *features* d'entrée le spectre représenté par chaque pixel. La documentation du module *[Neighbors](https://scikit-learn.org/stable/modules/neighbors.html)* de scikit-learn peut être utile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4775985-9b34-4dd2-87ce-9da199b873cd",
   "metadata": {},
   "source": [
    "### Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f3b6fd-8cba-40fd-9486-240ddf9e6a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995b65a7-3b36-43fa-8471-05c2bffc3d16",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Appliquer une classification par k-plus proche voisin avec $k=5$ en utilisant comme *features* d'entrée les **coordonnées** des pixels (et pas les valeurs de réflectance)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d9cf9e-0625-4db2-a52c-9f2dbdd60438",
   "metadata": {},
   "source": [
    "### Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4e8344-6e95-4ea0-b02d-c6fc6d1b7a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X_coords_train, y_train)\n",
    "clf.score(X_coords_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19301834-4d25-4c8c-aa7f-2ff732500e58",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Que peut-on en déduire sur les corrélations spatiales dans le jeu de données ? Comment faut-il diviser le jeu de données en train/test pour que l'évaluation ne soit pas biaisée ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34897f06-8aa6-4ac8-87f3-b39b133c3738",
   "metadata": {},
   "source": [
    "### Correction\n",
    "\n",
    "Il séparer le jeu de données en deux régions disjointes, sans quoi le test se fera sur des pixels physiquement très proches des pixels utilisées pour l'entraînement, ce qui est très optimiste ! La preuve, en comparant un pixel avec ses cinq voisins les plus proches dans le jeu d'apprentissage, on obtient >90% de bonne classification alors que le modèle ne prend même pas en compte le spectre de ce qui se trouve au sol."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10654f03-0270-4a50-a99f-7a7eb65b3d3a",
   "metadata": {},
   "source": [
    "Pour que notre évaluation soit plus rigoureuse, nous allons donc séparer le jeu de données, de façon plus ou moins arbitraire, en créant une grille rectangulaire de 10 cases. Chaque bloc de la grille sera soit en train, soit en test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb865dc-6e2d-49ad-b635-4b1df1ae74ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_2d = np.zeros_like(pavia_gt)\n",
    "h, w = groups_2d.shape\n",
    "idx = 0\n",
    "for i in range(0, h, h // 5):\n",
    "    for j in range(0, w, int(w / 2)):\n",
    "        groups_2d[i:i+h//5, j:j+int(w / 2)] = idx\n",
    "        idx += 1\n",
    "\n",
    "groups = groups_2d[pavia_gt != 0]\n",
    "\n",
    "fig = plt.figure(figsize=(15, 9))\n",
    "plt.imshow((pavia_rgb - pavia_rgb.min()) / pavia_rgb.max())\n",
    "plt.imshow(groups_2d, cmap=\"tab10\", alpha=0.5)\n",
    "plt.title(\"Groupes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c2f3d5-dedb-4d6c-a35d-12d390ca8735",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Quelle est la stratégie de validation croisée la plus adaptée ? Vous pouvez consulter la liste des stratégies implémentées par [sklearn](https://scikit-learn.org/stable/api/sklearn.model_selection.html) pour vous aider."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46736d8-f893-48c1-9dd4-9e4536cce170",
   "metadata": {},
   "source": [
    "### Correction\n",
    "\n",
    "Dans ce cas précis, le $k$-fold par groupe (*GroupKFold*) est la méthode la plus appropriée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402edf18-c65c-4465-a9fd-d80c0446e970",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Divisez le jeu de données en deux (apprentissage et test) à l'aide de l'algorithme de validation croisé que vous avez choisi. Vous pouvez utiliser la documentation de [scikit-learn](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators-for-grouped-data) pour vous aider.\n",
    "\n",
    "Appliquez ensuite le classifieur de votre choix de scikit-learn en l'entraînant sur le jeu de données d'apprentissage, puis évaluez le jeu de données de validation. N'oubliez pas de faire attention à la métrique à utiliser (le jeu de données est-il équilibré ? y a-t-il des classes plus difficiles à prédire que d'autres ?).\n",
    "\n",
    "Répétez cette opération pour toutes les *folds* de la validation croisée. Qu'observez-vous ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d164714d-329d-43ca-87ba-3d078113857d",
   "metadata": {},
   "source": [
    "### Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f208a1-aa73-43d6-820f-e7c0beceb389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "gkf = GroupKFold(n_splits=3)\n",
    "scores = []\n",
    "\n",
    "for idx, (train, test) in enumerate(gkf.split(X, y, groups=groups)):\n",
    "    print(f\"=== Fold {idx+1} ===\")\n",
    "    X_train, y_train = X[train], y[train]\n",
    "    X_test, y_test = X[test], y[test]\n",
    "\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(score)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred, zero_division=1.0, labels=np.unique(y), target_names=[\"Asphalt\", \"Meadows\", \"Gravel\", \"Trees\", \"Painted metal sheets\", \"Bare Soil\" , \"Bitumen\", \"Self-Blocking Bricks\", \"Shadows\"]))\n",
    "    scores.append(score)\n",
    "\n",
    "    # Identifiant des blocs sur lesquels tester\n",
    "    group_idx = [i for i in np.unique(groups[test])]\n",
    "    \n",
    "    predictions = np.zeros_like(pavia_gt)\n",
    "    group_mask = np.bitwise_and(pavia_gt != 0, np.isin(groups_2d, group_idx))\n",
    "    X_eval = pavia_image[group_mask]\n",
    "    predictions[group_mask] = clf.predict(X_eval)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    fig.add_subplot(1,2,1)\n",
    "    plt.imshow(pavia_gt, cmap=\"Pastel1\")\n",
    "    plt.title(\"Vérité terrain\")\n",
    "    fig.add_subplot(1,2,2)\n",
    "    plt.imshow(predictions, cmap=\"Pastel1\")\n",
    "    plt.title(\"Prédictions\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6689022c-3658-479f-8dab-84d89621b784",
   "metadata": {},
   "source": [
    "### Correction\n",
    "\n",
    "Les performances varient beaucoup pour chaque *fold* car les classes n'y sont pas uniformément représentées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fd649f-64b5-40b8-89d1-ecad3644f2e9",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Tracez la courbe du score moyen du modèle estimé par la validation croisée avec $k$ partitions en augmentant $k$, par exemple de 1 à 10. Représentez également l'écart-type de ce score. Que constatez-vous ?\n",
    "\n",
    "**Note**: si les temps de calcul sont trop longs avec une SVM linéaire (`LinearSVC`), vous pouvez la remplacer par une approximation utilisant la descente de gradient : `sklearn.linear_model.SGDClassifier` (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html). Vous pouvez aussi utiliser la fonction `cross_val_score()` de scikit-learn en spécifiant `n_jobs>1` pour paralléliser les calculs sur plusieurs cœurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff21fef-ebd1-4858-8593-2f70bfacbbdf",
   "metadata": {},
   "source": [
    "### Correction\n",
    "\n",
    "En augmentant le nombre de partitions dans la validation croisée, l'estimation du score se stabilise et devient plus robuste : la variance augmente mais l'estimateur converge vers le « vrai » score de généralisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92636ab-8562-4db7-a2e6-573047331be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "n_splits = range(2, 11)\n",
    "mean_score = []\n",
    "std_score = []\n",
    "\n",
    "for k in tqdm(n_splits):\n",
    "    gkf = GroupKFold(n_splits=k)\n",
    "    clf = SGDClassifier(alpha=1e-2)\n",
    "    scores = cross_val_score(clf, X, y, cv=gkf.split(X, y, groups=groups), n_jobs=-1)\n",
    "    mean_score.append(np.mean(scores))\n",
    "    std_score.append(np.std(scores))\n",
    "\n",
    "mean_score, std_score = np.array(mean_score), np.array(std_score)\n",
    "\n",
    "plt.fill_between(n_splits, mean_score - std_score, mean_score + std_score, alpha=0.2)\n",
    "plt.plot(n_splits, mean_score)\n",
    "plt.xlabel(\"$k$\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42763b45-bdb4-4ef3-aeb8-3ac8498f751d",
   "metadata": {},
   "source": [
    "## Recherche d'hyperparamètres\n",
    "\n",
    "La SVM linéaire a pour principal hyperparamètre le facteur de régularisation $C$. Pour rappel, contrôle le compromis entre la largeur de la marge et le nombre d'erreurs de classification commises par le modèle.\n",
    "\n",
    "Pour déterminer la valeur de cet hyperparamètre, nous allons effectuer une recherche d'hyperparamètres par grille (*GridSearch*). scikit-learn implémente un algorithme de recherche systématique qui gère automatiquement la validation croisée : [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).\n",
    "\n",
    "Pour commencer, nous allons définir la liste des valeurs que nous voulons tester pour $C$. Par exemple, nous pouvons choisir 5 valeurs différentes, de $10^{-3}$ à 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ae7735-a1db-4ab5-8a98-efbfc06acbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'C': [10e-3, 10e-2, 0.1, 1.0, 10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28925b1f-cb44-4675-b2d2-afde2d3248b9",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant définir la recherche par grille. Attention, on ne peut pas se contenter de la validation croisée par défaut de scikit-learn (qui effectue un $k$-fold). On va explicitement spécifiquer qu'il faut utiliser la validation croisée groupée définie plus haut, à l'aide du paramètre `cv=` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b4368c-a021-4100-a4a9-334026248ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "grid_search = GridSearchCV(LinearSVC(), grid, cv=gkf.split(X, y, groups=groups), n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd48f85e-6b6a-4752-b648-1862c5eb6ec4",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Combien de modèles vont être entraînés lors de cette recherche par grille ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9bbec4-3be5-4fde-8521-4e5c064b400a",
   "metadata": {},
   "source": [
    "### Correction\n",
    "\n",
    "En supposant un $k$-fold avec $k=5$, il y aura 26 modèles entraînés ($k$ modèles pour chaque point de la grille, soit $5\\times5$, plus un modèle final ré-entraîné avec le meilleur hyperparamètre)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be2961c-8953-4e77-828d-0dcb2b0d3c3c",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Appliquer cette *GridSearch* sur le jeu de données. Quelle est la valeur optimale de $C$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3151ac6c-330c-4936-b418-1af6b1842c1e",
   "metadata": {},
   "source": [
    "### Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476f450b-a214-4adb-9416-aff840b0acdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595161f4-3ed2-4c0b-8259-3644d323ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3189c89c-aec1-459c-99f9-b267f3770e1a",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3b8e4b-bf6d-4939-960a-098930aff369",
   "metadata": {},
   "source": [
    "Dans ce cas, le jeu de données est annoté, c'est-à-dire que l'on dispose d'étiquettes de classe pour chaque observation. Cela nous permet d'entraîner des modèles *supervisés*. Toutefois, ce n'est pas toujours le cas. Si nous n'avions pas d'étiquettes, une option consiste à réaliser une classification automatique à l'aide d'une méthode de *clustering*, par exemple $k$-*means*. Dans ce cas, il n'y a pas forcément d'intérêt à séparer le jeu de données en apprentissage et validation, car nous n'avons pas de données annotées sur lesquelles calculer une vérité terrain.\n",
    "\n",
    "Avec scikit-learn, il est possible d'utiliser l'objet [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) pour utiliser cet algorithme :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b7ceb-e396-4432-8f41-dc5ceb2485ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X = pavia_image.reshape(-1, 103)\n",
    "\n",
    "kmeans = KMeans(n_clusters=10)\n",
    "labels = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902b1a6b-a608-4d78-b831-2085ddd688a8",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "À l'aide de matplotlib, affichez la carte de l'université de Pavie colorisé selon les clusters déterminés par K-Means. Comparez visuellement à la vérité terrain pour différentes valeurs de $k$. Qu'en pensez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae0c5d-7789-4df0-994c-2201f08bf4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.imshow((pavia_rgb - pavia_rgb.min()) / pavia_rgb.max())\n",
    "plt.title(\"Image pseudo-RGB\")\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.imshow(labels.reshape(*pavia_gt.shape), cmap=\"Pastel1\")\n",
    "plt.title(\"K-Means\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f80692-5c7c-45f7-9230-5728967bcca6",
   "metadata": {},
   "source": [
    "## Pour aller plus loin : classification d'images sur EuroSAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c6033d-7f22-4054-8cd4-99e81dce3488",
   "metadata": {},
   "source": [
    "Pour aller plus loin, nous allons nous intéresser au jeu de\n",
    "données [EuroSAT](https://github.com/phelber/EuroSAT), qui est une\n",
    "base d’images contenant :\n",
    "\n",
    "- 10 classes (bâtiments industriels, bâtiments\n",
    "  résidentiels, cultures saisonnières, cultures permanentes, rivières,\n",
    "  lacs & mers, végétation herbacée, routes/autoroutes, pâturages et\n",
    "  forêts).  \n",
    "- Il y a 270000 images au total (162000 pour l'apprentissage, 5400 pour la validation et 5400 pour l'évaluation).\n",
    "- Les images sont de taille $ 64\\times64 $. Les images que\n",
    "  nous allons utiliser sont en couleur (RGB) mais il existe une version\n",
    "  multispectrale utilisant 13 longueurs d’onde différentes.  \n",
    "\n",
    "Pour simplifier la prise en mains, nous allons la bibliothèque [`datasets`](https://huggingface.co/docs/datasets/v1.2.0/index.html) qui permet d'importer directement ce jeu de données en une seule commande. Commençons par visualiser quelques images :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620acf6a-a7da-4a8b-bf8e-d13262d50905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "eurosat = load_dataset(\"blanchon/EuroSAT_RGB\")\n",
    "\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "for idx, data in enumerate(eurosat['train'].shuffle()):\n",
    "    if idx >= 10:\n",
    "        break\n",
    "    fig.add_subplot(1, 10, idx+1)\n",
    "    plt.imshow(data['image'])\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(data['filename'].split('_')[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0ac2ec-1aac-4b08-a16f-1cc06a1c6e85",
   "metadata": {},
   "source": [
    "Il s'agit comme indiqué précédemment d'images Sentinel-2 à 10m/px de résolution. Plus précisément, il s'agit des bandes dans le domaine visible, formant une pseudo-image RGB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1258997e-0e6c-491b-bb92-25ce60a73801",
   "metadata": {},
   "source": [
    "La fonction `create_dataset` ci-dessous permet de convertir le jeu de données EuroSAT au format attendu par scikit-learn, c'est-à-dire des tableaux NumPy. Elle transforme le jeu de données en deux tableaux `X` (contenant les images) et `y` (content les étiquettes des classes). Les images transformées en descripteurs (*features*). Pour l'instant, on se contente de redimensionner les images au format $32\\times32$ et de la transformer en vecteur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7752066b-d5a0-4346-babf-9780f4eb09cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# Exemple de redimensionnement d'image avec PIL\n",
    "im = eurosat['train'][0]['image']\n",
    "im.resize((32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2ed89e-2933-426c-97b4-7a0080569f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def create_dataset(dataset):\n",
    "    X, y = [], []\n",
    "    for data in tqdm(dataset):\n",
    "        image, label = data['image'], data['label']\n",
    "        features = np.array(image.resize((32, 32))).ravel()\n",
    "        X.append(features)\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddfc132-cc29-4908-b62e-dde1f22879b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_dataset(eurosat['train'])\n",
    "X_val, y_val = create_dataset(eurosat['validation'])\n",
    "X_test, y_test = create_dataset(eurosat['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d56ce28-1db1-40fe-8c51-59951b12886c",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Utilisez le classifieur de votre choix de scikit-learn et appliquez-le sur le jeu de données. Comparez les performances de différents classifieurs avec différents paramètres *sur le jeu de validation*. N'oubliez pas de faire attention à la métrique à utiliser (le jeu de données est-il équilibré ? y a-t-il des classes plus difficiles à prédire que d'autres ?)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6da838-ee2c-42ad-ad2c-c1229c44adc0",
   "metadata": {},
   "source": [
    "### Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedb6405-b2d1-42c8-a7a8-919182edbb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm = LinearSVC()\n",
    "svm.fit(X_train, y_train)\n",
    "svm.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95f2b86-a335-467e-b7fb-0bbbe9fdf8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "knn.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0ea66b-997f-497c-ad43-597fa5141b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06fc280-0323-40ae-95ed-24d30fc31c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_val, rf.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299463ab-aa87-4c43-b2cd-0f58ed70e2da",
   "metadata": {},
   "source": [
    "### Question : pour aller encore plus loin\n",
    "\n",
    "Répétez l'expérience précédente mais en utilisant d'autres descripteurs pour les images. Par exemple, vous pouvez utiliser les descripteurs HOG de scikit-image (`skimage.feature.hog`), d'autres facteurs de redimensionnement de l'image,  un histogramme de couleurs ou les descripteurs profonds calculés à l'aide de la fonction `extract_deep_features` ci-dessous. Quels descripteurs obtiennent les meilleurs résultats ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b90d329-f257-4b08-a1d0-8825915313a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models import efficientnet_b0\n",
    "from torchvision.models import EfficientNet_B0_Weights\n",
    "\n",
    "net = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
    "net.classifier = torch.nn.Sequential(*list(net.classifier.children())[:-3])\n",
    "print(net)\n",
    "\n",
    "def extract_deep_features(net, image):\n",
    "    batch = EfficientNet_B0_Weights.DEFAULT.transforms()(image).unsqueeze(0)\n",
    "    if torch.cuda.is_available():\n",
    "        net = net.to(\"cuda\")\n",
    "        batch = batch.to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        return net(batch).squeeze().to(\"cpu\").numpy()\n",
    "\n",
    "extract_deep_features(eurosat['train'][0]['image']).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8828ef-53ad-4df9-acbe-e4ac8f56d2ad",
   "metadata": {},
   "source": [
    "### Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f712ef-47f7-4c8f-b66e-c095f86d50fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset):\n",
    "    X, y = [], []\n",
    "    for data in tqdm(dataset):\n",
    "        image, label = data['image'], data['label']\n",
    "        features = extract_deep_features(net, image)\n",
    "        #features = np.array(image.resize((8,8))).ravel()\n",
    "        #features = hog(image, cells_per_block=(1,1), channel_axis=-1)\n",
    "        X.append(features)\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = create_dataset(eurosat['train'])\n",
    "X_val, y_val = create_dataset(eurosat['validation'])\n",
    "X_test, y_test = create_dataset(eurosat['test'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3532a83-d59f-4bdb-aba8-782acd21ee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "svm = SGDClassifier(alpha=1e-2)\n",
    "svm.fit(X_train, y_train)\n",
    "svm.score(X_val, y_val)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_val, svm.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216e92c2-f767-4b12-88b7-902b3b2a98dd",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "Évaluez votre meilleur modèle sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f81095a-ecba-41d5-8d11-11fff393893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2478cf74-3276-4b36-b93d-07eed0094f94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
